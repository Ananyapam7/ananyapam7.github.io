---
layout: papersshelf
permalink: /papersshelf/
title: Papers Shelf
description: A collection of some of the best articles on various topics. Keeping an organized list helps in building mental models and quickly remembering the crux of the work.
nav: true
nav_order: 1
---
<div id="chart"></div>

<script>
const papers = [
  {
    "title": "Solving SPDE giving a Mat√©rn random field using the FEM",
    "author": "H. Bakka",
    "year": 2018,
    "link": "https://arxiv.org/abs/1803.03765",
    "abstract": "",
    "math": 80,
    "statistics": 15,
    "comp_sci": 5,
    "finance": 0
  },
  {
    "title": "The Recovery Theorem",
    "author": "Ross, S.",
    "year": 2015,
    "link": "https://www.jstor.org/stable/30035052",
    "abstract": "Shows how to recover the natural probability measure R from market prices of derivative securities.",
    "math": 0,
    "statistics": 20,
    "comp_sci": 10,
    "finance": 70
  },
  {
    "title": "Variable Selection Methods in regression models for binary data",
    "author": "S. Bag",
    "year": 2017,
    "link": "https://arxiv.org/abs/1601.00670",
    "abstract": "In this paper, we explore four main typologies (test-based, penalty-based, screening-based, and tree-based) of frequentist variable selection methods in logistic regression setup.",
    "math": 0,
    "statistics": 95,
    "comp_sci": 5,
    "finance": 0
  },
  {
    "title": "Neural Additive Models",
    "author": "Agarwal, R., Frosst, N., Zhang, X., Caruana, R., and Hinton, G.",
    "year": 2020,
    "link": "https://arxiv.org/abs/2004.13912",
    "abstract": "Interpretable Machine Learning with Neural Nets",
    "math": 10,
    "statistics": 30,
    "comp_sci": 60,
    "finance": 0
  },
  {
    "title": "NAMLSS: Neural Additive Models for Location Scale and Shape",
    "author": "Thielmann, A., Kruse, R., Kneib, T., Safken, B.",
    "year": 2023,
    "link": "https://arxiv.org/abs/2301.11862",
    "abstract": "Distributional Regression using Machine Learning",
    "math": 10,
    "statistics": 30,
    "comp_sci": 60,
    "finance": 0
  },
  {
    "title": "Attention is All You Need",
    "author": "Vaswani, A.",
    "year": 2017,
    "link": "https://arxiv.org/abs/1706.03762",
    "abstract": "Proposed the Transformer architecture, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely.",
    "math": 10,
    "statistics": 20,
    "comp_sci": 70,
    "finance": 0
  },
  {
    "title": "Tab-Transformer: Tabular Data Modeling Using Contextual Embeddings",
    "author": "Huang, X., Khetan, A., Cvitkovic, M., & Karnin, Z.",
    "year": 2020,
    "link": "https://arxiv.org/abs/2012.06678v1",
    "abstract": "Built upon self-attention based Transformers. ",
    "math": 10,
    "statistics": 20,
    "comp_sci": 70,
    "finance": 0
  }
];
</script>