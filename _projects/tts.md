---
layout: page
title: Speech Enhancement in TTS systems
description: Google Winter of Code 2022
img: assets/img/clean_audio_spectrogram.png
importance: 3
category: Major
---

This was a winter of code research project aimed at speech enhancement of speech generated by text-to-speech models.

The speech generated by many TTS models had some ambient noise and noise-like artifacts. 
We worked on post-processing to reduce and remove those artifacts. Along with removing the noise, we also wished to quantify the noise and how clear our audio became after we applied our method. So we were also interested in developing *metrics* for quantifying the speech clarity.

## Datasets-

We used the following datasets for testing our methods-
- [NOIZEUS](https://ecs.utdallas.edu/loizou/speech/noizeus/) dataset
- Skit TTS dataset

## Speech Enhancement Methods

Speech enhancement methods could be broadly classified into two categories - 

### [Signal Processing](https://github.com/skit-ai/woc-tts-enhancement/tree/main/Filters)

This used traditional analytical filters which removed noise, either by assuming an additive noise, or by assuming an orthogonal direct sum decomposition of the noise into the clean and the pure noise signals. Statistical techniques like MMSE, MAP, MLE estimation fell into this category as well.

We implemented and tested the following methods-

- Kalman Filter
- Wiener Filter
- Oversubtraction/ Spectral Flooring
- Bayesian MMSE Filter
- Bayesian MMSE Log Filter

### Deep Learning

These were relatively new and advanced and were based on training. Some popular examples of this were the [Facebook Denoiser](https://github.com/facebookresearch/denoiser), [SeGAN](https://github.com/santi-pdp/segan_pytorch), and [RNN-Noise](https://github.com/xiph/rnnoise).

## [Metrics](https://github.com/skit-ai/woc-tts-enhancement/tree/main/Metrics)

We implemented and tested the following metrics-

- Perceptual Evaluation of Speech Quality (PESQ, narrow and wide band)
- Short-Time Objective Intelligibility (STOI) 
- F0 Frame Error (FFE)
- Gross Pitch Error (GPE)
- Mel Cepstral Distortion (MCD, both versions) 
- Voicing Error Decision (VED)  
- Mean Speech Distortion (MSD)
- Word Error Rate (WER)

These filter methods worked really well on the NOIZEUS dataset, however, they were not the best when it came to TTS models. The results of applying the filters on the NOIZUES as well as the TTS dataset had been discussed in detail [here](https://docs.google.com/presentation/d/12zHLefbkZoakgsf8_EFHNvmXPyeizbsL/edit?usp=sharing&ouid=103201416325155759704&rtpof=true&sd=true). Hence, we needed to resort to deep learning methods! 

This repo could be used for real-life speech denoisement purposes. Most importantly, it provided implementations of crucial metrics which could be used for measuring the amount of distortion/clarity of the speech.

## Installation

To install, we simply cloned the repository and installed the requirements

```
git clone https://github.com/skit-ai/woc-tts-enhancement
cd woc-tts-enhancement
pip install -r requirements.txt
```

Here are various links related to the project if you're interested

- [Blog Link](https://tech.skit.ai/woc/)

- [Devfolio Project Link](https://devfolio.co/projects/speech-enhancement-and-metrics-in-tts-systems-e9f9)

- [Project Report Link](https://docs.google.com/document/d/1X5S557QPCkSC1q0EK3GntNVv-IzIkUbA4SNJ2ZRbGfE/edit?usp=sharing)